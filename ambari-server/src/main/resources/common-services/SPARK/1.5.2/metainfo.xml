<?xml version="1.0"?>
<!--Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/
-->
<metainfo>
  <schemaVersion>2.0</schemaVersion>
  <services>
    <service>
      <name>SPARK</name>
      <displayName>Spark</displayName>
      <comment>Apache Spark is a fast and general engine for large-scale data processing.</comment>
      <version>1.5.2</version>
      <components>
        <component>
          <name>SPARK_HISTORY_SERVER</name>
          <displayName>Spark History Server</displayName>
          <category>MASTER</category>
          <cardinality>1</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
             </auto-deploy>
           </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/job_history_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
        </component>
        
        <component>
          <name>SPARK_JDBC_SERVER</name>
          <displayName>Spark JDBC Server</displayName>
          <category>MASTER</category>
          <cardinality>1</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>TEZ/TEZ_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>HIVE/HIVE_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/spark_jdbc_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
        </component>
        
        <component>
          <name>SPARK_LIVY_SERVER</name>
          <displayName>Spark Livy Server</displayName>
          <category>MASTER</category>
          <cardinality>1</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>SPARK/SPARK_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/spark_livy_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
        </component>
        
        <component>
          <name>SPARK_CLIENT</name>
          <displayName>Spark Client</displayName>
          <category>CLIENT</category>
          <cardinality>1+</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>TEZ/TEZ_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>HIVE/HIVE_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/spark_client.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
        </component>
      </components>

      <osSpecifics>
        <osSpecific>
          <osFamily>redhat5,redhat6,suse11</osFamily>
          <packages>
            <package>
              <name>livy-server</name>
            </package>
            <package>
              <name>spark</name>
            </package>
            <!--package>
              <name>lzo</name>
            </package>
            <package>
              <name>hadoop-lzo-native</name>
            </package>
            <package>
              <name>hadoop-lzo</name>
            </package-->
          </packages>
        </osSpecific>
        <osSpecific>
          <osFamily>ubuntu12</osFamily>
          <packages>
            <package>
              <name>livy-server</name>
            </package>
            <package>
              <name>spark</name>
            </package>
            <!--package>
              <name>lzo</name>
            </package>
            <package>
              <name>hadoop-lzo-native</name>
            </package>
            <package>
              <name>hadoop-lzo</name>
            </package-->
          </packages>
        </osSpecific>
      </osSpecifics>

      <configuration-dependencies>
        <config-type>spark-defaults</config-type>
        <config-type>livy-defaults</config-type>
        <config-type>core-site</config-type>
        <config-type>hdfs-site</config-type>
        <config-type>yarn-site</config-type>
        <!--  config-type>spark-env</config-type>
        <config-type>spark-log4j-properties</config-type>
        <config-type>spark-metrics-properties</config-type>
        <config-type>spark-javaopts-properties</config-type-->
      </configuration-dependencies>

      <commandScript>
        <script>scripts/service_check.py</script>
        <scriptType>PYTHON</scriptType>
        <timeout>300</timeout>
      </commandScript>

      <requiredServices>
        <service>YARN</service>
        <service>HIVE</service>
	<service>HDFS</service>
        <!-- service>TEZ</service-->
      </requiredServices>
    </service>
  </services>
</metainfo>
